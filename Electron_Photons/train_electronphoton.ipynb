{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of aliversion_electronphoton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo498ucQwt2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKGLod_pyT2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7NlubExodsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch_geometric.transforms\n",
        "from torch_geometric.transforms import knn_graph\n",
        "import torch_geometric.data\n",
        "import torch \n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance_matrix\n",
        "import torch\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch_geometric.nn import knn_graph\n",
        "import os \n",
        "\n",
        "from torch.utils.data import *\n",
        "from functools import partial\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oscUfco4LXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b22bb5fd-b77b-4c4a-dfb6-0798a4ae9f24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWU7C2D74bbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=50, help='Initial learning rate.') #100\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlr5poTlwwJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import *\n",
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None \n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        # Preprocessing\n",
        "        #data['X'] = np.float32(data['X'][0]) \n",
        "        data['X'] = torch.Tensor(data['X'][0])\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0tScMazEwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loader(datasets, batch_size, cut, random_sampler=False):\n",
        "    dset = ConcatDataset([ParquetDataset(dataset) for dataset in datasets])\n",
        "    idxs = np.random.permutation(len(dset))\n",
        "    if random_sampler: \n",
        "        random_sampler = sampler.SubsetRandomSampler(idxs[:cut])\n",
        "    else: \n",
        "        random_sampler = None \n",
        "    data_loader = DataLoader(dataset=dset, batch_size=batch_size, shuffle=False, num_workers=10, sampler=random_sampler, pin_memory=True)\n",
        "    return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufP5oAlv4T_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6db35a08-a3d2-4e5a-bb53-baa26b886293"
      },
      "source": [
        "cd drive/My\\ Drive/ElPhotons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ElPhotons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZU441jzIuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = ['ElectronData.h5.snappy.parquet','PhotonData.h5.snappy.parquet']\n",
        "data_loader = get_data_loader(datasets, args.batch_size, cut = None, random_sampler = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdryZNd3AibR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def jets(datei,labels,number1,number2):\n",
        "\n",
        "    cols = None\n",
        "\n",
        "    graphs=[]\n",
        "\n",
        "    for i in range(number1,number2):\n",
        "\n",
        "      ecal=datei[i].cuda()\n",
        "\n",
        "      xhit2,yhit2=torch.nonzero(ecal,as_tuple=True)  ## Select hits in detector\n",
        "\n",
        "      eneEcal=-torch.log(ecal[xhit2,yhit2])*10 ## Select energies of hits\n",
        "\n",
        "      feats=torch.stack((xhit2.float(),yhit2.float(),eneEcal),dim=1) ## concatenate x,y locations and energies (3 features in total)\n",
        "\n",
        "      cords=feats[:,[0,1]] ## cords = x,y coordinates \n",
        "\n",
        "      #if cords.shape[0]>=10: ## just to make sure a sample is not empty \n",
        "\n",
        "      edge_index = knn_graph(cords, k=6, batch=None, loop=True,num_workers=10)  ## Create knn graph adjacency matrix \n",
        "\n",
        "      donnees=Data(x=feats,edge_index=edge_index,label=labels[i]) ## Create graph data with feature matrix x and adjacency matrix edge_index\n",
        "      \n",
        "      graphs.append(donnees)\n",
        "\n",
        "    return graphs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2jT43EJGzqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1d09981b-8a5a-4641-ebb8-24ff561e9c35"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aliversion_electronphoton.ipynb\n",
            "ElectronData.h5.snappy.parquet\n",
            "PhotonData.h5.snappy.parquet\n",
            "\u001b[0m\u001b[01;34mQuarkGluonClassification\u001b[0m/\n",
            "SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
            "SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5.snappy.parquet\n",
            "SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5.snappy.parquet\n",
            "SinglePhotonPt50_IMGCROPS_n249k_RHv2.hdf5\n",
            "test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PLuWK0Fwr1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ep_model#DiffAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSQIPUpwIXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=ep_model.GraphClass(3,64,128,256,128,64,32, 0.3)#DiffAE.GraphAE()\n",
        "model.train()\n",
        "model.to(device)#.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uhVdiHY_fNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njSgFz7zwSmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model3.parameters(), lr=args.lr, weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU2WtJK6xSqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## generate list to count nodes for each graph\n",
        "def nodeCounter(samples):\n",
        "    inds=[]\n",
        "    for k in samples:\n",
        "        inds.append(k['x'].shape[0])\n",
        "    return inds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMxMRStZxbZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ref(bsize,nodeC,i1,i2):\n",
        "  maxC=np.max(np.array(nodeC))\n",
        "  maxC=2000#maxC + (4 - maxC % 4) ##max num of nodes 1161%4\n",
        "  refMat=np.zeros((bsize,maxC)) ## matrix of zeros\n",
        "  for pi in range(i1,i2):##10\n",
        "    refMat[bsize-(i2-pi),:nodeC[pi]]=1 ## fill ones \n",
        "  return refMat,maxC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY3rA_DUyfOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def assigner(nodelist):\n",
        "  fin=[]\n",
        "  countit=0\n",
        "  for m in nodelist:\n",
        "      fin.append(np.repeat(countit,m))\n",
        "      countit+=1\n",
        "  return np.array(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs29jExP3Emg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from optimizer import loss_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScWL694ARh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.cuda.amp import GradScaler, autocast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ9Q2_mHxJrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(y_true, y_prob):\n",
        "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
        "    y_prob = y_prob > 0.5\n",
        "    return (y_true == y_prob).sum().item() / y_true.size(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHDA2ZkExnKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5849008f-8ee3-484c-9fd5-5e0e10ccf855"
      },
      "source": [
        "import time\n",
        "for epoch in range(50):\n",
        "      #model.train()\n",
        "  count=0\n",
        "  c1,c2=0,args.batch_size\n",
        "  epLoss=0\n",
        "  t = time.time()\n",
        "  for i, data in enumerate(data_loader):\n",
        "        ecal2 = data['X'][:,0,:,:].cuda()\n",
        "        labels=data['y'][0].cuda()\n",
        "        rawGraph=jets(ecal2,labels,0,args.batch_size) ##Generating graphs from raw data \n",
        "        nodeCount=nodeCounter(rawGraph)\n",
        "        lengs=torch.LongTensor(np.hstack(assigner(np.array(nodeCount[c1:c2])-c1))).cuda()\n",
        "        \n",
        "        compress=torch_geometric.data.Batch.from_data_list(rawGraph)\n",
        "\n",
        "        gra=compress.x.to(device)\n",
        "        adj=compress.edge_index.to(device)\n",
        "\n",
        "        count+=1\n",
        "        refMat,maxCount=ref(args.batch_size,nodeCount,c1,c2)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        mask=torch.from_numpy(refMat).to(device) \n",
        "        #maxi=torch.from_numpy(np.array(maxCount)).to(device)\n",
        "\n",
        "        r1= model3(gra,adj,lengs.to(device),mask,2000)\n",
        "\n",
        "        #sparse=to_sparse_batch(r1, adj1, mask=torch.LongTensor(mask).cuda())\n",
        "\n",
        "        loss = loss_function(r1,labels.unsqueeze_(1))/args.batch_size    \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        cur_loss = loss.item()\n",
        "        \n",
        "        epLoss+=float(cur_loss)\n",
        "\n",
        "        #c1+=args.batch_size\n",
        "        #c2+=args.batch_size\n",
        "        if count%1250==0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "            t = time.time()\n",
        "        if count%10==0:\n",
        "            print(get_accuracy(labels.squeeze_(1),r1.squeeze_(1)))\n",
        "\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model3.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch':epoch,\n",
        "        'loss': loss,\n",
        "        'epLoss':epLoss\n",
        "        }, './loadBatches_b16_pool3.pth')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.48\n",
            "0.5\n",
            "0.46\n",
            "0.5\n",
            "0.56\n",
            "0.54\n",
            "0.34\n",
            "0.56\n",
            "0.54\n",
            "0.42\n",
            "0.58\n",
            "0.42\n",
            "0.46\n",
            "0.44\n",
            "0.48\n",
            "0.48\n",
            "0.46\n",
            "0.44\n",
            "0.56\n",
            "0.56\n",
            "0.62\n",
            "0.54\n",
            "0.62\n",
            "0.52\n",
            "0.32\n",
            "0.56\n",
            "0.6\n",
            "0.52\n",
            "0.56\n",
            "0.48\n",
            "0.4\n",
            "0.48\n",
            "0.52\n",
            "0.58\n",
            "0.48\n",
            "0.62\n",
            "0.48\n",
            "0.46\n",
            "0.5\n",
            "0.64\n",
            "0.56\n",
            "0.48\n",
            "0.56\n",
            "0.5\n",
            "0.38\n",
            "0.42\n",
            "0.42\n",
            "0.54\n",
            "0.44\n",
            "0.6\n",
            "0.38\n",
            "0.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f44c5a8c906c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mepLoss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}