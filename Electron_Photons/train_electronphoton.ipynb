{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aliversion_electronphoton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo498ucQwt2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3195b013-9940-4fef-f70a-fa740c27d2b3"
      },
      "source": [
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.5.1+cu101 in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: torchvision==0.6.1+cu101 in /usr/local/lib/python3.6/dist-packages (0.6.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu101) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKGLod_pyT2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52e40d38-0175-4af2-d5b6-32dc5d229adf"
      },
      "source": [
        "\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-scatter\n",
            "  Found existing installation: torch-scatter 2.0.5\n",
            "    Uninstalling torch-scatter-2.0.5:\n",
            "      Successfully uninstalled torch-scatter-2.0.5\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.5)\n",
            "Installing collected packages: torch-sparse\n",
            "  Found existing installation: torch-sparse 0.6.7\n",
            "    Uninstalling torch-sparse-0.6.7:\n",
            "      Successfully uninstalled torch-sparse-0.6.7\n",
            "Successfully installed torch-sparse-0.6.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.5.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-cluster\n",
            "  Found existing installation: torch-cluster 1.5.7\n",
            "    Uninstalling torch-cluster-1.5.7:\n",
            "      Successfully uninstalled torch-cluster-1.5.7\n",
            "Successfully installed torch-cluster-1.5.7\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "  Using cached https://pytorch-geometric.com/whl/torch-1.5.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-spline-conv\n",
            "  Found existing installation: torch-spline-conv 1.2.0\n",
            "    Uninstalling torch-spline-conv-1.2.0:\n",
            "      Successfully uninstalled torch-spline-conv-1.2.0\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.6/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.5)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: ase in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (3.20.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.1+cu101)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7NlubExodsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch_geometric.transforms\n",
        "from torch_geometric.transforms import knn_graph\n",
        "import torch_geometric.data\n",
        "import torch \n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance_matrix\n",
        "import torch\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch_geometric.nn import knn_graph\n",
        "import os \n",
        "\n",
        "from torch.utils.data import *\n",
        "from functools import partial\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oscUfco4LXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b22bb5fd-b77b-4c4a-dfb6-0798a4ae9f24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWU7C2D74bbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=50, help='Initial learning rate.') #100\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlr5poTlwwJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import *\n",
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None \n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        # Preprocessing\n",
        "        #data['X'] = np.float32(data['X'][0]) \n",
        "        data['X'] = torch.Tensor(data['X'][0])\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG0tScMazEwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loader(datasets, batch_size, cut, random_sampler=False):\n",
        "    dset = ConcatDataset([ParquetDataset(dataset) for dataset in datasets])\n",
        "    idxs = np.random.permutation(len(dset))\n",
        "    if random_sampler: \n",
        "        random_sampler = sampler.SubsetRandomSampler(idxs[:cut])\n",
        "    else: \n",
        "        random_sampler = None \n",
        "    data_loader = DataLoader(dataset=dset, batch_size=batch_size, shuffle=False, num_workers=10, sampler=random_sampler, pin_memory=True)\n",
        "    return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufP5oAlv4T_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6db35a08-a3d2-4e5a-bb53-baa26b886293"
      },
      "source": [
        "cd drive/My\\ Drive/ElPhotons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ElPhotons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZU441jzIuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = ['ElectronData.h5.snappy.parquet','PhotonData.h5.snappy.parquet']\n",
        "data_loader = get_data_loader(datasets, args.batch_size, cut = None, random_sampler = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdryZNd3AibR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def jets(datei,labels,number1,number2):\n",
        "\n",
        "    cols = None\n",
        "\n",
        "    graphs=[]\n",
        "\n",
        "    for i in range(number1,number2):\n",
        "\n",
        "      ecal=datei[i].cuda()\n",
        "\n",
        "      xhit2,yhit2=torch.nonzero(ecal,as_tuple=True)  ## Select hits in detector\n",
        "\n",
        "      eneEcal=-torch.log(ecal[xhit2,yhit2])*10 ## Select energies of hits\n",
        "\n",
        "      feats=torch.stack((xhit2.float(),yhit2.float(),eneEcal),dim=1) ## concatenate x,y locations and energies (3 features in total)\n",
        "\n",
        "      cords=feats[:,[0,1]] ## cords = x,y coordinates \n",
        "\n",
        "      #if cords.shape[0]>=10: ## just to make sure a sample is not empty \n",
        "\n",
        "      edge_index = knn_graph(cords, k=6, batch=None, loop=True,num_workers=10)  ## Create knn graph adjacency matrix \n",
        "\n",
        "      donnees=Data(x=feats,edge_index=edge_index,label=labels[i]) ## Create graph data with feature matrix x and adjacency matrix edge_index\n",
        "      \n",
        "      graphs.append(donnees)\n",
        "\n",
        "    return graphs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2jT43EJGzqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1d09981b-8a5a-4641-ebb8-24ff561e9c35"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aliversion_electronphoton.ipynb\n",
            "ElectronData.h5.snappy.parquet\n",
            "PhotonData.h5.snappy.parquet\n",
            "\u001b[0m\u001b[01;34mQuarkGluonClassification\u001b[0m/\n",
            "SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\n",
            "SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5.snappy.parquet\n",
            "SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5.snappy.parquet\n",
            "SinglePhotonPt50_IMGCROPS_n249k_RHv2.hdf5\n",
            "test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1B7F5yBw8gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c834822-a273-4c0f-e48b-fdedaece12a2"
      },
      "source": [
        "cd QuarkGluonClassification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ElPhotons/QuarkGluonClassification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PLuWK0Fwr1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import VAE#DiffAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSQIPUpwIXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "601c5913-5694-4b65-9295-53f1c0d12034"
      },
      "source": [
        "model3=VAE.GraphAE(3,64,128,256,128,64,32, 0.3)#DiffAE.GraphAE()\n",
        "model3.train()\n",
        "model3.to(device)#.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphAE(\n",
              "  (sage1): DenseGCNConv(3, 64)\n",
              "  (sage2): DenseGCNConv(64, 128)\n",
              "  (poolit1): DenseGCNConv(128, 500)\n",
              "  (poolit2): DenseGCNConv(128, 250)\n",
              "  (poolit3): DenseGCNConv(64, 10)\n",
              "  (sage3): DenseGCNConv(128, 256)\n",
              "  (sage4): DenseGCNConv(256, 128)\n",
              "  (sage5): DenseGCNConv(128, 64)\n",
              "  (tr1): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (tr2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (fin): Linear(in_features=250, out_features=1, bias=True)\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (bano1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano2): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano3): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano5): BatchNorm1d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano6): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tahaLy3ryZsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6ba83e16-7ddc-47bb-eb7f-759514fffb80"
      },
      "source": [
        "\"\"\"\n",
        "checkpoint = torch.load('loadBatches_b16_nw8.pth')\n",
        "model3.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "for state in optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "model3.eval()\n",
        "model3.to(device)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ncheckpoint = torch.load('loadBatches_b16_nw8.pth')\\nmodel3.load_state_dict(checkpoint['model_state_dict'])\\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\\nfor state in optimizer.state.values():\\n    for k, v in state.items():\\n        if isinstance(v, torch.Tensor):\\n            state[k] = v.cuda()\\nmodel3.eval()\\nmodel3.to(device)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uhVdiHY_fNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = torch.cuda.amp.GradScaler() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njSgFz7zwSmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model3.parameters(), lr=args.lr, weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU2WtJK6xSqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## generate list to count nodes for each graph\n",
        "def nodeCounter(samples):\n",
        "    inds=[]\n",
        "    for k in samples:\n",
        "        inds.append(k['x'].shape[0])\n",
        "    return inds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMxMRStZxbZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ref(bsize,nodeC,i1,i2):\n",
        "  maxC=np.max(np.array(nodeC))\n",
        "  maxC=2000#maxC + (4 - maxC % 4) ##max num of nodes 1161%4\n",
        "  refMat=np.zeros((bsize,maxC)) ## matrix of zeros\n",
        "  for pi in range(i1,i2):##10\n",
        "    refMat[bsize-(i2-pi),:nodeC[pi]]=1 ## fill ones \n",
        "  return refMat,maxC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY3rA_DUyfOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def assigner(nodelist):\n",
        "  fin=[]\n",
        "  countit=0\n",
        "  for m in nodelist:\n",
        "      fin.append(np.repeat(countit,m))\n",
        "      countit+=1\n",
        "  return np.array(fin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs29jExP3Emg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from optimizer import loss_function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LScWL694ARh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from torch.cuda.amp import GradScaler, autocast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZ9Q2_mHxJrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(y_true, y_prob):\n",
        "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
        "    y_prob = y_prob > 0.5\n",
        "    return (y_true == y_prob).sum().item() / y_true.size(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHDA2ZkExnKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5849008f-8ee3-484c-9fd5-5e0e10ccf855"
      },
      "source": [
        "import time\n",
        "for epoch in range(50):\n",
        "      #model.train()\n",
        "  count=0\n",
        "  c1,c2=0,args.batch_size\n",
        "  epLoss=0\n",
        "  t = time.time()\n",
        "  for i, data in enumerate(data_loader):\n",
        "        ecal2 = data['X'][:,0,:,:].cuda()\n",
        "        labels=data['y'][0].cuda()\n",
        "        rawGraph=jets(ecal2,labels,0,args.batch_size) ##Generating graphs from raw data \n",
        "        nodeCount=nodeCounter(rawGraph)\n",
        "        lengs=torch.LongTensor(np.hstack(assigner(np.array(nodeCount[c1:c2])-c1))).cuda()\n",
        "        \n",
        "        compress=torch_geometric.data.Batch.from_data_list(rawGraph)\n",
        "\n",
        "        gra=compress.x.to(device)\n",
        "        adj=compress.edge_index.to(device)\n",
        "\n",
        "        count+=1\n",
        "        refMat,maxCount=ref(args.batch_size,nodeCount,c1,c2)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        mask=torch.from_numpy(refMat).to(device) \n",
        "        #maxi=torch.from_numpy(np.array(maxCount)).to(device)\n",
        "\n",
        "        r1= model3(gra,adj,lengs.to(device),mask,2000)\n",
        "\n",
        "        #sparse=to_sparse_batch(r1, adj1, mask=torch.LongTensor(mask).cuda())\n",
        "\n",
        "        loss = loss_function(r1,labels.unsqueeze_(1))/args.batch_size    \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        cur_loss = loss.item()\n",
        "        \n",
        "        epLoss+=float(cur_loss)\n",
        "\n",
        "        #c1+=args.batch_size\n",
        "        #c2+=args.batch_size\n",
        "        if count%1250==0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "            t = time.time()\n",
        "        if count%10==0:\n",
        "            print(get_accuracy(labels.squeeze_(1),r1.squeeze_(1)))\n",
        "\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model3.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch':epoch,\n",
        "        'loss': loss,\n",
        "        'epLoss':epLoss\n",
        "        }, './loadBatches_b16_pool3.pth')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.48\n",
            "0.5\n",
            "0.46\n",
            "0.5\n",
            "0.56\n",
            "0.54\n",
            "0.34\n",
            "0.56\n",
            "0.54\n",
            "0.42\n",
            "0.58\n",
            "0.42\n",
            "0.46\n",
            "0.44\n",
            "0.48\n",
            "0.48\n",
            "0.46\n",
            "0.44\n",
            "0.56\n",
            "0.56\n",
            "0.62\n",
            "0.54\n",
            "0.62\n",
            "0.52\n",
            "0.32\n",
            "0.56\n",
            "0.6\n",
            "0.52\n",
            "0.56\n",
            "0.48\n",
            "0.4\n",
            "0.48\n",
            "0.52\n",
            "0.58\n",
            "0.48\n",
            "0.62\n",
            "0.48\n",
            "0.46\n",
            "0.5\n",
            "0.64\n",
            "0.56\n",
            "0.48\n",
            "0.56\n",
            "0.5\n",
            "0.38\n",
            "0.42\n",
            "0.42\n",
            "0.54\n",
            "0.44\n",
            "0.6\n",
            "0.38\n",
            "0.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f44c5a8c906c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mepLoss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-LSm3IlJyCU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc7e18f9-86a2-468f-ba95-fc618f2fb35e"
      },
      "source": [
        "count\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "521"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF9Gj9NELLEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1146f79-da29-47a2-874c-26ee2bc394e6"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0142, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbiWeJ9HXK0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rawGraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzspKQOEXitP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "xhit2,yhit2=torch.nonzero(ecal2[2],as_tuple=True)  ## Select hits in detector\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYQ_J4PNXrMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xhit2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHF27GzsMbhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "eneEcal=ecal[xhit2,yhit2] ## Select energies of hits\n",
        "\n",
        "feats=torch.stack((xhit2.float(),yhit2.float(),eneEcal),dim=1) ## concatenate x,y locations and energies (3 features in total)\n",
        "\n",
        "cords=feats[:,[0,1]] ## cords = x,y coordinates \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT5OwvZTOEQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r1[:,nodeCount,:].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXWO5T0LW3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lossMSE=torch.nn.MSELoss()\n",
        "lossMSE(x2,gra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE-wrXNSJsVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testsets = ['../../parquets/Boosted_Jets_Sample-%i.snappy.parquet'%i for i in range(2,3)]\n",
        "testloader = get_data_loader(testsets, args.batch_size, cut = None, random_sampler = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0LlRK4XYrS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BEg7D_fzoiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "for epoch in range(1):\n",
        "      #model.train()\n",
        "  count=0\n",
        "  c1,c2=0,args.batch_size\n",
        "  epLoss=0\n",
        "  t = time.time()\n",
        "  model3.eval()\n",
        "  with torch.no_grad():\n",
        "    for i, data in enumerate(testloader):\n",
        "          ecal2 = data['X_jets'].cuda()\n",
        "          rawGraph=torchjets(ecal2,0,args.batch_size) ##Generating graphs from raw data \n",
        "          nodeCount=nodeCounter(rawGraph)\n",
        "          lengs=torch.LongTensor(np.hstack(assigner(np.array(nodeCount[c1:c2])-c1))).cuda()\n",
        "          \n",
        "          compress=torch_geometric.data.Batch.from_data_list(rawGraph)\n",
        "\n",
        "          gra=compress.x.to(device)\n",
        "          adj=compress.edge_index.to(device)\n",
        "\n",
        "          count+=1\n",
        "          refMat,maxCount=ref(args.batch_size,nodeCount,c1,c2)\n",
        "          \n",
        "          mask=torch.from_numpy(refMat).to(device)\n",
        "          #maxi=torch.from_numpy(np.array(maxCount)).to(device)\n",
        "\n",
        "          r1 ,adj1,mu,sig= model3(gra,adj,lengs.to(device),mask,2000)\n",
        "\n",
        "          loss = loss_function(r1,gra,nodeCount,lengs,2000,mu,sig)/args.batch_size\n",
        "\n",
        "          cur_loss = loss.item()\n",
        "          \n",
        "          epLoss+=float(cur_loss)\n",
        "\n",
        "\n",
        "          #c1+=args.batch_size\n",
        "          #c2+=args.batch_size\n",
        "          if count%20==0:\n",
        "              print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "              t = time.time()\n",
        "              break;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egy2I5Bc1uGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "#xmin, xmax = min(lis4[:,0]), max(lis4[:,0])\n",
        "#ymin, ymax = min(lis4[:,1]), max(lis4[:,1])\n",
        "%matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import LogNorm\n",
        "r12=r1[0].cpu().clone()\n",
        "xmin,xmax=0,125\n",
        "ymin,ymax=0,125\n",
        "binsxy = [int((xmax - xmin) / 50), int((ymax - ymin) / 50)]\n",
        "weights=np.exp(-r12[:,2])\n",
        "plt.figure(figsize=(7,6))\n",
        "sc = plt.scatter(r12[:,0],r12[:,1],c=weights,cmap='viridis', norm=LogNorm(),alpha=0.9)\n",
        "plt.colorbar(sc)\n",
        "check=np.arange(0,140,10)\n",
        "plt.xticks(check)\n",
        "plt.yticks(check)\n",
        "plt.grid()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXgaj6Xd16Ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}