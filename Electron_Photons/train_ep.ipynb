{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_ep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIrfZ0mOkovk",
        "outputId": "b1c8475e-9bbf-4046-aee3-6125ab0ad3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E-jmMVslOdf"
      },
      "source": [
        "#!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRNADPSmljRE",
        "outputId": "526107eb-44f1-4e40-d6f0-e75357020ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric\n",
        "\"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\\n!pip install torch-geometric\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn9beFQSlll8"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import torch_geometric.transforms\n",
        "from torch_geometric.transforms import knn_graph\n",
        "import torch_geometric.data\n",
        "import torch \n",
        "from torch_geometric.data import Data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.spatial import distance_matrix\n",
        "import torch\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch_geometric.nn import knn_graph\n",
        "import os \n",
        "\n",
        "from torch.utils.data import *\n",
        "from functools import partial\n",
        "import timeit"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZIK24z9loM9"
      },
      "source": [
        "import argparse\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--maxnodes', type=int, default=185, help='Max Nodes')\n",
        "parser.add_argument('--epochs', type=int, default=50, help='Number of epochs to train.')\n",
        "parser.add_argument('--batch_size', type=int, default=50, help='Initial learning rate.') #100\n",
        "\n",
        "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate.') #0.001\n",
        "parser.add_argument('--dropout', type=float, default=0.3, help='Dropout rate (1 - keep probability).')\n",
        "args = parser.parse_args([])\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i8bBdvAlqGN"
      },
      "source": [
        "from torch.utils.data import *\n",
        "class ParquetDataset(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.parquet = pq.ParquetFile(filename)\n",
        "        self.cols = None \n",
        "    def __getitem__(self, index):\n",
        "        data = self.parquet.read_row_group(index, columns=self.cols).to_pydict()\n",
        "        # Preprocessing\n",
        "        #data['X'] = np.float32(data['X'][0]) \n",
        "        data['X'] = torch.Tensor(data['X'][0])\n",
        "        return dict(data)\n",
        "    def __len__(self):\n",
        "        return self.parquet.num_row_groups"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibNPFjdmXCe"
      },
      "source": [
        "def get_data_loader(datasets, batch_size, cut, random_sampler=False):\n",
        "    dset = ConcatDataset([ParquetDataset(dataset) for dataset in datasets])\n",
        "    idxs = np.random.permutation(len(dset))\n",
        "    if random_sampler: \n",
        "        random_sampler = sampler.SubsetRandomSampler(idxs[:cut])\n",
        "    else: \n",
        "        random_sampler = None \n",
        "    data_loader = DataLoader(dataset=dset, batch_size=batch_size, shuffle=False, num_workers=10, sampler=random_sampler, pin_memory=True)\n",
        "    return data_loader"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQs3KsgymfiX",
        "outputId": "c7d5fea0-40a4-477b-f325-e4b9bed78722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My\\ Drive"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqrgeqb0mYfF"
      },
      "source": [
        "\n",
        "datasets = ['ElectronTrainData.h5.snappy.parquet','PhotonTrainData.h5.snappy.parquet']\n",
        "data_loader = get_data_loader(datasets, args.batch_size, cut = None, random_sampler = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcaEAyVmbC1"
      },
      "source": [
        "\n",
        "val_datasets = ['PhotonValData.h5.snappy.parquet','ElectronValData.h5.snappy.parquet']\n",
        "val_loader = get_data_loader(val_datasets, args.batch_size, cut = None, random_sampler = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ondwTCZ_mbfF"
      },
      "source": [
        "\n",
        "def jets(datei,labels,number1,number2):\n",
        "\n",
        "    cols = None\n",
        "\n",
        "    graphs=[]\n",
        "\n",
        "    for i in range(number1,number2):\n",
        "\n",
        "      ecal=datei[i].cuda()\n",
        "\n",
        "      xhit2,yhit2=torch.nonzero(ecal,as_tuple=True)  ## Select hits in detector\n",
        "\n",
        "      eneEcal=ecal[xhit2,yhit2]*50 ## Select energies of hits\n",
        "\n",
        "      feats=torch.stack((xhit2.float(),yhit2.float(),eneEcal),dim=1) ## concatenate x,y locations and energies (3 features in total)\n",
        "\n",
        "      cords=feats[:,[0,1]] ## cords = x,y coordinates \n",
        "\n",
        "      #if cords.shape[0]>=10: ## just to make sure a sample is not empty \n",
        "\n",
        "      #feats[:,0]/=125\n",
        "      #feats[:,1]/=125\n",
        "\n",
        "      edge_index = knn_graph(cords, k=6, batch=None, loop=True)  ## Create knn graph adjacency matrix \n",
        "\n",
        "      donnees=Data(x=feats,edge_index=edge_index,label=labels[i]) ## Create graph data with feature matrix x and adjacency matrix edge_index\n",
        "      \n",
        "      graphs.append(donnees)\n",
        "\n",
        "    return graphs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LN4rSN2mp9E"
      },
      "source": [
        "import ep_model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDsZK49umq_-",
        "outputId": "6d098ae9-43de-4d9d-c16a-cea6c3a8927f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "model=ep_model.GraphClass(3,64,128,128,256,128,64,args.maxnodes)\n",
        "model.train()\n",
        "model.to(device)#.cuda()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphClass(\n",
              "  (sage1): DenseSAGEConv(3, 64)\n",
              "  (sage2): DenseSAGEConv(64, 128)\n",
              "  (poolit1): Linear(in_features=64, out_features=50, bias=True)\n",
              "  (poolit2): Linear(in_features=128, out_features=15, bias=True)\n",
              "  (sage3): DenseSAGEConv(64, 128)\n",
              "  (sage5): DenseSAGEConv(128, 128)\n",
              "  (tr1): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (tr2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (fin): Linear(in_features=15, out_features=1, bias=True)\n",
              "  (drop4): Dropout(p=0.4, inplace=False)\n",
              "  (drop3): Dropout(p=0.3, inplace=False)\n",
              "  (drop2): Dropout(p=0.2, inplace=False)\n",
              "  (bano1): BatchNorm1d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano2): BatchNorm1d(185, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano3): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bano5): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT8lI-UrmsDO"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g4mD675mta2"
      },
      "source": [
        "\n",
        "## generate list to count nodes for each graph\n",
        "def nodeCounter(samples):\n",
        "    inds=[]\n",
        "    for k in samples:\n",
        "        inds.append(k['x'].shape[0])\n",
        "    return inds"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3mBvHElmuv3"
      },
      "source": [
        "def ref(bsize,nodeC,i1,i2):\n",
        "  maxC=np.max(np.array(nodeC))\n",
        "  maxC=args.maxnodes#maxC + (4 - maxC % 4) ##max num of nodes 1161%4\n",
        "  refMat=np.zeros((bsize,maxC)) ## matrix of zeros\n",
        "  for pi in range(i1,i2):##10\n",
        "    refMat[bsize-(i2-pi),:nodeC[pi]]=1 ## fill ones \n",
        "  return refMat,maxC"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o90_w_SUmvmG"
      },
      "source": [
        "def assigner(nodelist):\n",
        "  fin=[]\n",
        "  countit=0\n",
        "  for m in nodelist:\n",
        "      fin.append(np.repeat(countit,m))\n",
        "      countit+=1\n",
        "  return np.array(fin)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGyIO_D1mwk8"
      },
      "source": [
        "from optimizer import loss_function"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5NO6xPamx5G"
      },
      "source": [
        "def get_accuracy(y_true, y_prob):\n",
        "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
        "    y_prob = y_prob > 0.5\n",
        "    return (y_true == y_prob).sum().item() / y_true.size(0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt0EV_hBmzll",
        "outputId": "b3ee9ff3-aaff-423f-e69f-a790bd9b920c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import time\n",
        "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
        "for epoch in range(50):\n",
        "      #model.train()\n",
        "  count=0\n",
        "  c1,c2=0,args.batch_size\n",
        "  epLoss=0\n",
        "  t = time.time()\n",
        "  for i, data in enumerate(data_loader):\n",
        "        ecal2 = data['X'][:,0,:,:].cuda()\n",
        "        labels=data['y'][0].cuda()\n",
        "        rawGraph=jets(ecal2,labels,0,args.batch_size) ##Generating graphs from raw data \n",
        "        nodeCount=nodeCounter(rawGraph)\n",
        "        lengs=torch.LongTensor(np.hstack(assigner(np.array(nodeCount[c1:c2])))).cuda()\n",
        "        \n",
        "        compress=torch_geometric.data.Batch.from_data_list(rawGraph)\n",
        "\n",
        "        gra=compress.x.to(device).clone()\n",
        "        adj=compress.edge_index.to(device).clone()\n",
        "\n",
        "        count+=1\n",
        "        #refMat,maxCount=ref(args.batch_size,nodeCount,c1,c2)\n",
        "\n",
        "        whole,mask=to_dense_batch(gra, lengs, fill_value=0, max_num_nodes=args.maxnodes)#refMat.shape[1])\n",
        "        wholeAdj=to_dense_adj(adj, lengs, edge_attr=None, max_num_nodes=args.maxnodes)#refMat.shape[1]).cuda()\n",
        "        \n",
        "        whole=whole.cuda()\n",
        "        wholeAdj=wholeAdj.cuda()\n",
        "        mask=mask.cuda()\n",
        "        lengs=lengs.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        r1= model(whole,wholeAdj,lengs,mask,args.maxnodes)\n",
        "\n",
        "        loss = loss_function(r1,labels.unsqueeze_(1))/args.batch_size    \n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        cur_loss = loss.item()\n",
        "        \n",
        "        epLoss+=float(cur_loss)\n",
        "\n",
        "        #c1+=args.batch_size\n",
        "        #c2+=args.batch_size\n",
        "        if count%3200==0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(epLoss/count),\"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "            t = time.time()\n",
        "            print(get_accuracy(labels.squeeze_(1),r1.squeeze_(1)))\n",
        "\n",
        "  torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'epoch':epoch,\n",
        "        'loss': loss,\n",
        "        'epLoss':epLoss\n",
        "        }, './loadBatches_b16_pool3.pth')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Xmeda5mkGq"
      },
      "source": [
        "gra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgjGgkDr7Zi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}